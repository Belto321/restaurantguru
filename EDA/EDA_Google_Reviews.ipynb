{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def filter_reviews_incremental(parquet_file, output_file=\"filtered_reviews.jsonl\"):\n",
    "    \"\"\"\n",
    "    Filtra las reviews que estén en el conjunto de gmap_id provenientes del archivo parquet de restaurantes filtrados.\n",
    "    Escribe los resultados línea por línea en el archivo de salida sin guardarlas todas en memoria.\n",
    "\n",
    "    Args:\n",
    "        parquet_file (str): Ruta del archivo parquet que contiene los restaurantes filtrados.\n",
    "        output_file (str): Nombre del archivo de salida en formato JSON lines.\n",
    "    \"\"\"\n",
    "\n",
    "    # Leer el parquet con los restaurantes filtrados\n",
    "    if not os.path.exists(parquet_file):\n",
    "        print(f\"No se encontró el archivo {parquet_file}.\")\n",
    "        return\n",
    "\n",
    "    df = pd.read_parquet(parquet_file)\n",
    "    # Extraer el conjunto de gmap_ids\n",
    "    gmap_ids_set = set(df[\"gmap_id\"].dropna().unique())\n",
    "\n",
    "    # Abrir el archivo de salida en modo escritura\n",
    "    # El formato será JSON lines: cada línea un JSON con la review filtrada.\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as out_f:\n",
    "\n",
    "        # Recorrer las carpetas que empiecen con \"review-\"\n",
    "        for dir_name in os.listdir(\".\"):\n",
    "            if os.path.isdir(dir_name) and dir_name.startswith(\"review-\"):\n",
    "                i = 1\n",
    "                while True:\n",
    "                    review_file = os.path.join(dir_name, f\"{i}.json\")\n",
    "                    if not os.path.exists(review_file):\n",
    "                        break\n",
    "                    with open(review_file, \"r\", encoding=\"utf-8\") as rf:\n",
    "                        for line in rf:\n",
    "                            line = line.strip()\n",
    "                            if not line:\n",
    "                                continue\n",
    "                            try:\n",
    "                                review = json.loads(line)\n",
    "                            except json.JSONDecodeError:\n",
    "                                continue\n",
    "\n",
    "                            if \"gmap_id\" in review and review[\"gmap_id\"] in gmap_ids_set:\n",
    "                                # Escribir la línea directamente al archivo, sin almacenar en memoria\n",
    "                                # Convertimos review a string nuevamente (ya viene de line, podemos usar la original)\n",
    "                                # pero para asegurarnos, la reconstruimos desde el dict:\n",
    "                                out_f.write(json.dumps(review, ensure_ascii=False) + \"\\n\")\n",
    "                    i += 1\n",
    "\n",
    "    print(f\"Proceso completado. Las reviews filtradas se han guardado en formato JSON lines en {output_file}.\")\n",
    "\n",
    "\n",
    "\n",
    "parquet_path = \"../Data_cleaned/metadatosgoogle/filtered_top_10_states.parquet\"  # Ajustar según corresponda\n",
    "filter_reviews_incremental(parquet_path, \"../Data_cleaned/Googl_Reviews/filtered_reviews.jsonl\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

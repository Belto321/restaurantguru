{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ABSA utilizando el modelo DistilBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [30:09<00:00, 30.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Análisis completado y guardado en absa_results_optimized.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Paso 1: Cargar datos preprocesados\n",
    "data_path = \"sample_preprocessed.parquet\"\n",
    "data = pd.read_parquet(data_path)\n",
    "\n",
    "# Paso 2: Configurar el modelo y tokenizer (DistilBERT fine-tuned para clasificación)\n",
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Optimización para CPU\n",
    "device = torch.device(\"cpu\")  # Asegura que use CPU\n",
    "model.to(device)\n",
    "\n",
    "# Crear pipeline con truncamiento automático de textos largos\n",
    "sentiment_pipeline = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=-1,  # -1 indica que se usará CPU\n",
    "    truncation=True,  # Trunca automáticamente los textos largos\n",
    "    max_length=512  # Límite para DistilBERT\n",
    ")\n",
    "\n",
    "# Paso 3: Realizar ABSA por lotes\n",
    "def analyze_sentiment_batch(data_batch, aspects):\n",
    "    \"\"\"\n",
    "    Analiza un lote de datos, evaluando el sentimiento para cada aspecto.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for _, row in data_batch.iterrows():\n",
    "        text = row[\"text_clean\"]\n",
    "        row_results = []\n",
    "        for aspect in aspects:\n",
    "            input_text = f\"What do people think about {aspect}? {text}\"\n",
    "            sentiment = sentiment_pipeline(input_text)\n",
    "            row_results.append({\n",
    "                \"aspect\": aspect,\n",
    "                \"sentiment\": sentiment[0][\"label\"],\n",
    "                \"score\": sentiment[0][\"score\"]\n",
    "            })\n",
    "        results.append(row_results)\n",
    "    return results\n",
    "\n",
    "# Definir aspectos\n",
    "aspects = [\"service\", \"food\", \"price\", \"ambiance\"]\n",
    "\n",
    "# Dividir los datos en lotes y procesarlos\n",
    "batch_size = 50  # Ajusta según la capacidad de tu CPU\n",
    "all_results = []\n",
    "for i in tqdm(range(0, len(data), batch_size)):\n",
    "    batch = data.iloc[i:i+batch_size]\n",
    "    batch_results = analyze_sentiment_batch(batch, aspects)\n",
    "    all_results.extend(batch_results)\n",
    "\n",
    "# Agregar los resultados al DataFrame\n",
    "data[\"aspect_sentiments\"] = all_results\n",
    "\n",
    "# Paso 4: Guardar los resultados\n",
    "output_path = \"absa_results_optimized.parquet\"\n",
    "data.to_parquet(output_path, index=False)\n",
    "print(f\"Análisis completado y guardado en {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Análisis completado y guardado en absa_results_optimized.csv\n"
     ]
    }
   ],
   "source": [
    "# Paso 4: Guardar los resultados en CSV\n",
    "output_path_csv = \"absa_results_optimized.csv\"\n",
    "data.to_csv(output_path_csv, index=False)\n",
    "print(f\"Análisis completado y guardado en {output_path_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo filtrado creado y guardado en filtered_absa_results.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Paso 1: Cargar el archivo CSV generado anteriormente\n",
    "input_csv_path = \"absa_results_optimized.csv\"\n",
    "data = pd.read_csv(input_csv_path)\n",
    "\n",
    "# Paso 2: Filtrar las columnas deseadas\n",
    "columns_to_keep = [\"id\", \"user_id\", \"stars\", \"date\", \"id_business\", \"text_clean\", \"sentiment\", \"aspect_sentiments\"]\n",
    "filtered_data = data[columns_to_keep]\n",
    "\n",
    "# Paso 3: Guardar el nuevo archivo CSV\n",
    "output_csv_path = \"filtered_absa_results.csv\"\n",
    "filtered_data.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Archivo filtrado creado y guardado en {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo filtrado creado y guardado en filtered_absa_results_2.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Paso 1: Cargar el archivo CSV generado anteriormente\n",
    "input_csv_path = \"absa_results_optimized.csv\"\n",
    "data = pd.read_csv(input_csv_path)\n",
    "\n",
    "# Paso 2: Filtrar las columnas deseadas\n",
    "columns_to_keep = [\"stars\", \"date\", \"id_business\", \"sentiment\", \"aspect_sentiments\"]\n",
    "filtered_data = data[columns_to_keep]\n",
    "\n",
    "# Paso 3: Guardar el nuevo archivo CSV\n",
    "output_csv_path = \"filtered_absa_results_2.csv\"\n",
    "filtered_data.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Archivo filtrado creado y guardado en {output_csv_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataScience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

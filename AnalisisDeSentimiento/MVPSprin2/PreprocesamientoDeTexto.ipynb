{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento de Texto\n",
    "\n",
    "- Limpieza básica de texto:\n",
    "\n",
    "Convertir todo a minúsculas.\n",
    "\n",
    "Eliminar caracteres especiales, números y puntuación.\n",
    "\n",
    "Quitar espacios en blanco innecesarios.\n",
    "\n",
    "- Eliminación de palabras vacías (stopwords):\n",
    "\n",
    "Quitar palabras comunes que no aportan significado (e.g., \"el\", \"la\", \"y\").\n",
    "\n",
    "- Normalización de texto:\n",
    "\n",
    "Lematización o stemming para reducir palabras a su raíz.\n",
    "\n",
    "- Tokenización:\n",
    "\n",
    "Dividir el texto en palabras individuales.\n",
    "\n",
    "- Eliminación opcional de palabras irrelevantes:\n",
    "\n",
    "Quitar palabras específicas que no son útiles para tu caso de uso (e.g., nombres de negocios, palabras repetidas)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparar el Entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/carla/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/carla/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/carla/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Descargar recursos necesarios de NLTK\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configurar Stopwords y Lematizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar stopwords y lematizador\n",
    "stop_words = set(stopwords.words('english'))  # Cambiar a 'spanish' si trabajas con español\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear Funciones de Preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función 1: Limpieza Básica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Realiza una limpieza básica del texto:\n",
    "    - Convierte a minúsculas.\n",
    "    - Elimina caracteres especiales, números y puntuación.\n",
    "    \"\"\"\n",
    "    text = text.lower()  # Convertir a minúsculas\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Eliminar caracteres no alfabéticos\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función 2: Eliminar Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    \"\"\"\n",
    "    Elimina palabras vacías (stopwords) del texto.\n",
    "    \"\"\"\n",
    "    words = text.split()  # Tokenizar\n",
    "    words = [word for word in words if word not in stop_words]  # Filtrar\n",
    "    return ' '.join(words)  # Reconstruir el texto\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función 3: Lematización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    \"\"\"\n",
    "    Aplica lematización a cada palabra del texto.\n",
    "    \"\"\"\n",
    "    words = text.split()  # Tokenizar\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]  # Lematizar\n",
    "    return ' '.join(words)  # Reconstruir el texto\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicar las Funciones Paso a Paso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer archivo limpio\n",
    "reviews = pd.read_csv('reviews_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar limpieza básica\n",
    "reviews['cleaned_text'] = reviews['review_text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar stopwords\n",
    "reviews['no_stopwords_text'] = reviews['cleaned_text'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar lematización\n",
    "reviews['processed_text'] = reviews['no_stopwords_text'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         review_text  \\\n",
      "0  The salads were lackluster though with well wr...   \n",
      "1  Love this place. Great little restaurant, with...   \n",
      "2  A classy restaurant to match the charm of the ...   \n",
      "3                     Great atmosphere and good food   \n",
      "4                                          Good food   \n",
      "\n",
      "                                      processed_text  \n",
      "0  salad lackluster though well written descripti...  \n",
      "1  love place great little restaurant unique dish...  \n",
      "2  classy restaurant match charm inn make reserva...  \n",
      "3                         great atmosphere good food  \n",
      "4                                          good food  \n"
     ]
    }
   ],
   "source": [
    "# Verificar los resultados\n",
    "print(reviews[['review_text', 'processed_text']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardar el Archivo Procesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo preprocesado guardado como: reviews_preprocessed.csv\n"
     ]
    }
   ],
   "source": [
    "# Guardar el archivo procesado\n",
    "output_path = 'reviews_preprocessed.csv'\n",
    "reviews.to_csv(output_path, index=False)\n",
    "print(f\"Archivo preprocesado guardado como: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proyectoML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
